{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import timedelta, datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   person_id event_concept_name    svcdate\n",
      "0      23655                  B 2004-12-29\n",
      "1      15796                  A 2001-02-13\n",
      "2        861                  F 2012-05-03\n",
      "3       5391                  B 2010-12-26\n",
      "4      29803                  D 2010-01-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 设置随机种子以确保可复现性\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 创建数据生成的基本参数\n",
    "num_rows = 100000\n",
    "person_id_range = (1, 30000)  # 假设有3000个不同的患者\n",
    "disease_list = ['A', 'B', 'C', 'D','E','F']  # 假设疾病列表\n",
    "date_range = (datetime(2000, 1, 1), datetime(2023, 12, 31))  # 日期范围从2019年到2023年\n",
    "\n",
    "# 生成随机数据\n",
    "data = {\n",
    "    'person_id': np.random.randint(*person_id_range, size=num_rows),\n",
    "    'event_concept_name': np.random.choice(disease_list, size=num_rows),\n",
    "    'svcdate': [date_range[0] + timedelta(days=random.randint(0, (date_range[1] - date_range[0]).days)) for _ in range(num_rows)]\n",
    "}\n",
    "\n",
    "# 创建DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df.head())  # 打印前几行以查看数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   person_id event_concept_name    svcdate\n",
      "0     296897                  D 2017-02-02\n",
      "1     132004                  C 2014-11-26\n",
      "2     217059                  C 2010-05-08\n",
      "3     250961                  E 2007-06-13\n",
      "4      53492                  D 2017-04-19\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 设置随机种子以确保可复现性\n",
    "random.seed(41)\n",
    "np.random.seed(41)\n",
    "\n",
    "# 创建数据生成的基本参数\n",
    "num_rows = 1000000\n",
    "person_id_range = (1, 300000)  # 假设有3000个不同的患者\n",
    "disease_list = ['A', 'B', 'C', 'D','E','F']  # 假设疾病列表\n",
    "date_range = (datetime(2000, 1, 1), datetime(2023, 12, 31))  # 日期范围从2019年到2023年\n",
    "\n",
    "# 生成随机数据\n",
    "data2 = {\n",
    "    'person_id': np.random.randint(*person_id_range, size=num_rows),\n",
    "    'event_concept_name': np.random.choice(disease_list, size=num_rows),\n",
    "    'svcdate': [date_range[0] + timedelta(days=random.randint(0, (date_range[1] - date_range[0]).days)) for _ in range(num_rows)]\n",
    "}\n",
    "\n",
    "# 创建DataFrame\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "print(df2.head())  # 打印前几行以查看数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiseaseCount:\n",
    "    \"\"\"\n",
    "    Creata a class and load original data frame to class and make data processing to count patients in each year\n",
    "    \"\"\"\n",
    "    def __init__(self, name):\n",
    "        \"\"\"\n",
    "        Initiate class with None attributes\n",
    "\n",
    "        Args:\n",
    "            name (str): give a name to the class\n",
    "        \"\"\"\n",
    "        self.original_df = None # Initiate the original data frame with none\n",
    "        self.unique_id_df = None # Initiate the unique patients id data frame \n",
    "        self.date_order_df = None # Initiate the date order dataframe\n",
    "        self.year_counts_df = None # Initiate the year count dataframe\n",
    "        self.lag_counts_df = None # Initiate the lag count dataframe\n",
    "        self.lag_num = None # Initiate the lag num\n",
    "        self.name = name # Give the argument name to the class\n",
    "        self.new_year_data = None # Initiate the new year data dataframe\n",
    "    \n",
    "    def load_data(self, data):\n",
    "        \"\"\"\n",
    "        load the data to the object as the original table aka df\n",
    "        \n",
    "        args:\n",
    "        - data(dataframe or other format table): the data which will be added into the object as the\n",
    "                original table aka df, could be a dataframe, also could be other format and transfer\n",
    "                to dataframe\n",
    "        \"\"\"\n",
    "        \n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            self.original_df = data\n",
    "        else:\n",
    "            self.original_df = pd.DataFrame(data)\n",
    "            \n",
    "    def unique_patient(self):\n",
    "        \"\"\"\n",
    "        Only keep the unique patient ID \n",
    "        \"\"\"\n",
    "        \n",
    "        if self.original_df is None:\n",
    "            raise ValueError(\"Data is not loaded. Please load data first using `load_data` method.\")\n",
    "\n",
    "        # sort by person id and svcdate\n",
    "        sorted_df = self.original_df.sort_values(by=['person_id', 'svcdate'])\n",
    "\n",
    "        # get the first condition recording and generate a copy\n",
    "        first_records = sorted_df.drop_duplicates(subset=['person_id'], keep='first').copy()\n",
    "        \n",
    "        self.unique_id_df = first_records\n",
    "        \n",
    "    def svcdate_order(self):\n",
    "        \"\"\"\n",
    "        Prepare for count function to reorder the dataframe as svc_data order\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.unique_id_df is None:\n",
    "            raise ValueError(\"Data is not loaded. Please load data first using `unique_patient` method.\")\n",
    "        \n",
    "        \n",
    "        sorted_df = self.unique_id_df.sort_values(by = ['svcdate'])\n",
    "        \n",
    "        self.date_order_df = sorted_df\n",
    "        \n",
    "    def year_counts(self):\n",
    "        \"\"\"\n",
    "        Make yearly counts by the years\n",
    "        \"\"\"\n",
    "        if self.date_order_df is None:\n",
    "            raise ValueError(\"Data is not loaded. Please load data first using `svcdate_order` method.\")\n",
    "    \n",
    "        # Extract the year from the 'svcdate' column\n",
    "        self.date_order_df['year'] = self.date_order_df['svcdate'].dt.year\n",
    "        \n",
    "        # Count the unique patients per year\n",
    "        year_counts_df = self.date_order_df.groupby('year').agg(patient_count=('person_id', 'nunique')).reset_index()\n",
    "        \n",
    "        self.year_counts_df = year_counts_df\n",
    "        \n",
    "    def generate_lag(self, lag = 3):\n",
    "        \"\"\"\n",
    "        Generate the dataframe with showing lag years based on the 'year_counts_df'.\n",
    "        \n",
    "        args:\n",
    "        - lag(int type): The number of lag years to calculate.\n",
    "        \"\"\"    \n",
    "        temp_df = self.year_counts_df.copy()\n",
    "        \n",
    "        year_to_count = self.year_counts_df.set_index('year')['patient_count'].to_dict()\n",
    "        \n",
    "        for i in range(1, lag + 1):\n",
    "            temp_df[f'lag_{i}'] = temp_df['year'].apply(lambda y: year_to_count.get(y - i, 0))\n",
    "            \n",
    "        temp_df = temp_df.iloc[lag:].reset_index(drop=True)    \n",
    "        \n",
    "        self.lag_num = lag\n",
    "        self.lag_counts_df = temp_df\n",
    "        \n",
    "    def generate_next_yearlag(self):\n",
    "        \"\"\"\n",
    "        Generate the next year lag prepare for prediction\n",
    "        \"\"\"\n",
    "        # Get the maximum year in the current lag_counts_df\n",
    "        last_year = self.lag_counts_df['year'].max()\n",
    "        \n",
    "        # Create a dictionary to hold the new row data\n",
    "        new_year_data = {'year': last_year + 1}\n",
    "        \n",
    "        # Calculate lag values for the next year based on existing data\n",
    "        year_to_count = self.year_counts_df.set_index('year')['patient_count'].to_dict()\n",
    "        for i in range(1, self.lag_num + 1):\n",
    "            new_year_data[f'lag_{i}'] = year_to_count.get(last_year + 1 - i, 0)\n",
    "        self.new_year_data = pd.DataFrame([new_year_data]) \n",
    "        # Append this new row to lag_counts_df\n",
    "        # self.lag_counts_df = self.lag_counts_df.append(new_year_data, ignore_index=True)\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>patient_count</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>25480</td>\n",
       "      <td>29378</td>\n",
       "      <td>33684</td>\n",
       "      <td>39029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004</td>\n",
       "      <td>22269</td>\n",
       "      <td>25480</td>\n",
       "      <td>29378</td>\n",
       "      <td>33684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005</td>\n",
       "      <td>19321</td>\n",
       "      <td>22269</td>\n",
       "      <td>25480</td>\n",
       "      <td>29378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006</td>\n",
       "      <td>17016</td>\n",
       "      <td>19321</td>\n",
       "      <td>22269</td>\n",
       "      <td>25480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007</td>\n",
       "      <td>14666</td>\n",
       "      <td>17016</td>\n",
       "      <td>19321</td>\n",
       "      <td>22269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2008</td>\n",
       "      <td>13117</td>\n",
       "      <td>14666</td>\n",
       "      <td>17016</td>\n",
       "      <td>19321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2009</td>\n",
       "      <td>11255</td>\n",
       "      <td>13117</td>\n",
       "      <td>14666</td>\n",
       "      <td>17016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010</td>\n",
       "      <td>9782</td>\n",
       "      <td>11255</td>\n",
       "      <td>13117</td>\n",
       "      <td>14666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2011</td>\n",
       "      <td>8348</td>\n",
       "      <td>9782</td>\n",
       "      <td>11255</td>\n",
       "      <td>13117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2012</td>\n",
       "      <td>7269</td>\n",
       "      <td>8348</td>\n",
       "      <td>9782</td>\n",
       "      <td>11255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013</td>\n",
       "      <td>6455</td>\n",
       "      <td>7269</td>\n",
       "      <td>8348</td>\n",
       "      <td>9782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014</td>\n",
       "      <td>5641</td>\n",
       "      <td>6455</td>\n",
       "      <td>7269</td>\n",
       "      <td>8348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2015</td>\n",
       "      <td>4882</td>\n",
       "      <td>5641</td>\n",
       "      <td>6455</td>\n",
       "      <td>7269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016</td>\n",
       "      <td>4222</td>\n",
       "      <td>4882</td>\n",
       "      <td>5641</td>\n",
       "      <td>6455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017</td>\n",
       "      <td>3679</td>\n",
       "      <td>4222</td>\n",
       "      <td>4882</td>\n",
       "      <td>5641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018</td>\n",
       "      <td>3182</td>\n",
       "      <td>3679</td>\n",
       "      <td>4222</td>\n",
       "      <td>4882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019</td>\n",
       "      <td>2777</td>\n",
       "      <td>3182</td>\n",
       "      <td>3679</td>\n",
       "      <td>4222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020</td>\n",
       "      <td>2380</td>\n",
       "      <td>2777</td>\n",
       "      <td>3182</td>\n",
       "      <td>3679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021</td>\n",
       "      <td>2164</td>\n",
       "      <td>2380</td>\n",
       "      <td>2777</td>\n",
       "      <td>3182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022</td>\n",
       "      <td>1772</td>\n",
       "      <td>2164</td>\n",
       "      <td>2380</td>\n",
       "      <td>2777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023</td>\n",
       "      <td>1563</td>\n",
       "      <td>1772</td>\n",
       "      <td>2164</td>\n",
       "      <td>2380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  patient_count  lag_1  lag_2  lag_3\n",
       "0   2003          25480  29378  33684  39029\n",
       "1   2004          22269  25480  29378  33684\n",
       "2   2005          19321  22269  25480  29378\n",
       "3   2006          17016  19321  22269  25480\n",
       "4   2007          14666  17016  19321  22269\n",
       "5   2008          13117  14666  17016  19321\n",
       "6   2009          11255  13117  14666  17016\n",
       "7   2010           9782  11255  13117  14666\n",
       "8   2011           8348   9782  11255  13117\n",
       "9   2012           7269   8348   9782  11255\n",
       "10  2013           6455   7269   8348   9782\n",
       "11  2014           5641   6455   7269   8348\n",
       "12  2015           4882   5641   6455   7269\n",
       "13  2016           4222   4882   5641   6455\n",
       "14  2017           3679   4222   4882   5641\n",
       "15  2018           3182   3679   4222   4882\n",
       "16  2019           2777   3182   3679   4222\n",
       "17  2020           2380   2777   3182   3679\n",
       "18  2021           2164   2380   2777   3182\n",
       "19  2022           1772   2164   2380   2777\n",
       "20  2023           1563   1772   2164   2380"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = DiseaseCount(\"table1\")\n",
    "t2 = DiseaseCount(\"table2\")\n",
    "\n",
    "t1.load_data(data)\n",
    "t2.load_data(data2)\n",
    "\n",
    "t1.unique_patient()\n",
    "t2.unique_patient()\n",
    "\n",
    "t1.svcdate_order()\n",
    "t2.svcdate_order()\n",
    "\n",
    "t1.year_counts()\n",
    "t2.year_counts()\n",
    "\n",
    "t1.generate_lag()\n",
    "t2.generate_lag()\n",
    "\n",
    "t1.generate_next_yearlag()\n",
    "t2.generate_next_yearlag()\n",
    "t2.lag_counts_df\n",
    "\n",
    "# t1.year_counts_df\n",
    "# t2.year_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>1563</td>\n",
       "      <td>1772</td>\n",
       "      <td>2164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  lag_1  lag_2  lag_3\n",
       "0  2024   1563   1772   2164"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.new_year_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegModel:\n",
    "    def __init__(self, name):\n",
    "        \"\"\"\n",
    "        Initiate the Linear regression model \n",
    "        Args:\n",
    "            name ( str type ): give this model a name\n",
    "        \"\"\"\n",
    "        self.name = name # Give this linear regression model name\n",
    "        self.indep_df = None # initiate the independent variable table which is the X\n",
    "        self.dep_df = None # initiate the dependent variable table which is the Y\n",
    "        self.indep_nextyear_df = None # initiate the independent variable table which is the X\n",
    "        self.dep_nextyear_df = None # initiate the dependent variable table which is the Y\n",
    "        self.indep_name = None # initiate the independent name as None\n",
    "        self.dep_name = None # initiate the dependent name as None\n",
    "        self.models = None # initiate the regression model\n",
    "        self.combined_df = None # initiate the combined dataframe\n",
    "        self.combined_predictor = None # initiate the predictor param dataframe\n",
    "        self.lag_num = None # Initiate the lag number \n",
    "        self.prediction = None # Initiate the prediction part\n",
    "        self.lag_covariance = None # Initiate the lag covariance \n",
    "        \n",
    "        \n",
    "    def load_data(self, dep, indep):\n",
    "        \"\"\"\n",
    "        load the independent table and dependent table into this class\n",
    "        \n",
    "        args:\n",
    "            dep( object ): should be a object which is the dependent variable\n",
    "            indep( object ): should be a object which is the independent variable\n",
    "        \"\"\"\n",
    "        \n",
    "        if dep.lag_counts_df is None or indep.lag_counts_df is None:\n",
    "            raise ValueError(\"Data is not loaded. Please load data to ge` method.\")\n",
    "        \n",
    "        self.indep_df = indep.lag_counts_df\n",
    "        self.dep_df = dep.lag_counts_df\n",
    "        self.indep_nextyear_df = indep.new_year_data\n",
    "        self.dep_nextyear_df = dep.new_year_data\n",
    "        self.indep_name = indep.name\n",
    "        self.dep_name = dep.name\n",
    "        self.lag_num = dep.lag_num\n",
    "        \n",
    "    def combine_data(self):\n",
    "        \"\"\" \n",
    "        Generate combination data with the two dataframe\n",
    "        \"\"\"\n",
    "        \n",
    "        if  self.indep_df is None or self.dep_df is None:\n",
    "            raise ValueError(\"Data is not loaded. Please use load_data function firstly.\")\n",
    "        \n",
    "        if 'year' not in self.indep_df.columns or 'year' not in self.dep_df.columns:\n",
    "            raise ValueError(\"Both data tables must have a 'year' column to combine based on it.\")\n",
    "            \n",
    "        self.combined_df = pd.merge(self.dep_df, self.indep_df,  on='year', suffixes=( '_' + self.dep_name, '_' + self.indep_name))\n",
    "        start_year = self.combined_df['year'].min()\n",
    "        self.combined_df['T'] = self.combined_df['year'] - start_year + 1\n",
    "        self.combined_predictor = pd.merge(self.dep_nextyear_df, self.indep_nextyear_df,  on='year', suffixes=( '_' + self.dep_name, '_' + self.indep_name))\n",
    "        # self.combined_predictor.drop(['year'])\n",
    "        self.combined_predictor['T'] = self.combined_df['T'].iloc[-1] + 1\n",
    "        \n",
    "    def get_covarience(self):\n",
    "        \"\"\"\n",
    "        Calculate the covariance between table1 and table2 and add it to the combined dataframe.\n",
    "        \"\"\"\n",
    "        if self.combined_df is None:\n",
    "            raise ValueError(\"Data is not combined. Please use combine_data function first.\")\n",
    "        \n",
    "        overall_covariance = np.cov(self.combined_df['patient_count_table1'], self.combined_df['patient_count_table2'])[0, 1]\n",
    "        \n",
    "        self.combined_df['overall_covariance'] = overall_covariance\n",
    "        self.combined_predictor['overall_covariance'] = overall_covariance\n",
    "    \n",
    "    def calculate_lag_covariance(self):\n",
    "        \"\"\"\n",
    "        Calculate the lags covariance between table1 and table2 and add it to the combined dataframe.\n",
    "        \"\"\"\n",
    "        # if self.combined_df is None:\n",
    "        #     raise ValueError(\"Data is not combined. Please use combine_data function first.\")\n",
    "        \n",
    "        # table1_lags = np.array([self.combined_df[f'lag_{i}_'+self.dep_name] for i in range(1, self.lag_num+1)])\n",
    "        # table2_lags = np.array([self.combined_df[f'lag_{i}_'+self.indep_name] for i in range(1, self.lag_num+1)])\n",
    "        # covariance_matrix = np.cov(table1_lags, table2_lags)\n",
    "        # self.lag_covariance = covariance_matrix[0, 1]\n",
    "        # self.combined_df['lags_covariance'] = self.lag_covariance\n",
    "        \n",
    "        # if self.combined_predictor is None:\n",
    "        #     raise ValueError(\"Data is not predictor combined. Please use combine_data function first.\")\n",
    "        \n",
    "        # table1_lags_pred = np.array([self.combined_predictor[f'lag_{i}_'+self.dep_name] for i in range(1, self.lag_num+1)])\n",
    "        # table2_lags_pred = np.array([self.combined_predictor[f'lag_{i}_'+self.indep_name] for i in range(1, self.lag_num+1)])\n",
    "        # covariance_matrix_pred = np.cov(table1_lags_pred, table2_lags_pred)\n",
    "        # self.lag_covariance_pred = covariance_matrix_pred[0, 1]\n",
    "        # self.combined_predictor['lags_covariance'] = self.lag_covariance_pred\n",
    "        \n",
    "        def calculate_covariance(row, num_lags):\n",
    "            table1_lags = np.array([row[f'lag_{i}_table1'] for i in range(1, num_lags+1)])\n",
    "            table2_lags = np.array([row[f'lag_{i}_table2'] for i in range(1, num_lags+1)])\n",
    "            covariance_matrix = np.cov(table1_lags, table2_lags)\n",
    "            return covariance_matrix[0, 1]\n",
    "\n",
    "            # Compute the covariance for each row and store it in a new column\n",
    "        self.lag_covariance = self.combined_df.apply(calculate_covariance, num_lags= 3, axis=1)\n",
    "        self.combined_df['lags_variance'] = self.lag_covariance\n",
    "        \n",
    "        self.lag_covariance_pred = self.combined_predictor.apply(calculate_covariance, num_lags= 3, axis=1)\n",
    "        self.combined_predictor['lags_variance'] = self.lag_covariance_pred\n",
    "        \n",
    "    def fit_model(self):\n",
    "        \"\"\"\n",
    "        Fit the linear regression model using statsmodels and display the summary.\n",
    "        \"\"\"\n",
    "        if self.combined_df is None:\n",
    "            raise ValueError(\"Data is not combined. Please use combine_data function first.\")\n",
    "\n",
    "        # Assuming the dependent variable column is from dep_df and others are independent variables\n",
    "        X = self.combined_df.drop(['year', 'patient_count_' + self.dep_name, 'patient_count_' + self.indep_name], axis=1)\n",
    "        y = self.combined_df['patient_count_' + self.dep_name]\n",
    "        \n",
    "        # Add a constant to the model (for the intercept)\n",
    "        X = sm.add_constant(X)\n",
    "        \n",
    "        # Fit the model\n",
    "        model = sm.OLS(y, X).fit()\n",
    "        \n",
    "        # Store the model\n",
    "        self.models = model\n",
    "        \n",
    "        # Print the summary\n",
    "        # print(model.summary()) \n",
    "        \n",
    "    def generate_prediction(self):\n",
    "        \"\"\"\n",
    "        Predict the dependent variable next year patient count based on the linear regression model.\n",
    "        \"\"\"\n",
    "        if self.models is None:\n",
    "            raise ValueError(\"No model is fitted. Please use fit_model function first.\")\n",
    "        \n",
    "        \n",
    "        # Add a constant to the model (for the intercept)\n",
    "        next_year_data = self.combined_predictor.drop(['year'], axis=1).copy()\n",
    "        \n",
    "        next_year_data = sm.add_constant(next_year_data)\n",
    "        # print(next_year_data)\n",
    "        # Predict using the fitted model\n",
    "        prediction = self.models.predict(next_year_data)\n",
    "        # predicted_values = prediction[:, 0]\n",
    "        self.prediction = prediction\n",
    "        print(\"The forecast value for next year new patients count is \" + str(prediction.iloc[0]))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The forecast value for next year new patients count is 147.80572172505182\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>patient_count_table1</td> <th>  R-squared:         </th> <td>   0.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                     <td>OLS</td>         <th>  Adj. R-squared:    </th> <td>   0.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>Least Squares</td>    <th>  F-statistic:       </th> <td>   1860.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>               <td>Wed, 15 May 2024</td>   <th>  Prob (F-statistic):</th> <td>2.29e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                   <td>11:50:31</td>       <th>  Log-Likelihood:    </th> <td> -92.637</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>        <td>    21</td>        <th>  AIC:               </th> <td>   203.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>            <td>    12</td>        <th>  BIC:               </th> <td>   212.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>                <td>     8</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>        <td>nonrobust</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_1_table1</th>       <td>   -0.8256</td> <td>    0.289</td> <td>   -2.859</td> <td> 0.014</td> <td>   -1.455</td> <td>   -0.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_2_table1</th>       <td>   -0.5950</td> <td>    0.284</td> <td>   -2.098</td> <td> 0.058</td> <td>   -1.213</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_3_table1</th>       <td>   -0.3488</td> <td>    0.267</td> <td>   -1.309</td> <td> 0.215</td> <td>   -0.930</td> <td>    0.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_1_table2</th>       <td>    0.1193</td> <td>    0.083</td> <td>    1.444</td> <td> 0.174</td> <td>   -0.061</td> <td>    0.299</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_2_table2</th>       <td>    0.1205</td> <td>    0.066</td> <td>    1.832</td> <td> 0.092</td> <td>   -0.023</td> <td>    0.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_3_table2</th>       <td>    0.0148</td> <td>    0.065</td> <td>    0.226</td> <td> 0.825</td> <td>   -0.127</td> <td>    0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>T</th>                  <td>    4.1096</td> <td>    8.101</td> <td>    0.507</td> <td> 0.621</td> <td>  -13.540</td> <td>   21.759</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>overall_covariance</th> <td>-1.067e-05</td> <td> 3.48e-05</td> <td>   -0.307</td> <td> 0.764</td> <td>-8.65e-05</td> <td> 6.52e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lags_variance</th>      <td>    0.0002</td> <td>    0.000</td> <td>    1.371</td> <td> 0.195</td> <td>-9.87e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.094</td> <th>  Durbin-Watson:     </th> <td>   2.484</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.579</td> <th>  Jarque-Bera (JB):  </th> <td>   0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.046</td> <th>  Prob(JB):          </th> <td>   0.926</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.409</td> <th>  Cond. No.          </th> <td>7.30e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 7.3e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}      & patient\\_count\\_table1 & \\textbf{  R-squared:         } &     0.999   \\\\\n",
       "\\textbf{Model:}              &          OLS           & \\textbf{  Adj. R-squared:    } &     0.999   \\\\\n",
       "\\textbf{Method:}             &     Least Squares      & \\textbf{  F-statistic:       } &     1860.   \\\\\n",
       "\\textbf{Date:}               &    Wed, 15 May 2024    & \\textbf{  Prob (F-statistic):} &  2.29e-17   \\\\\n",
       "\\textbf{Time:}               &        11:50:31        & \\textbf{  Log-Likelihood:    } &   -92.637   \\\\\n",
       "\\textbf{No. Observations:}   &             21         & \\textbf{  AIC:               } &     203.3   \\\\\n",
       "\\textbf{Df Residuals:}       &             12         & \\textbf{  BIC:               } &     212.7   \\\\\n",
       "\\textbf{Df Model:}           &              8         & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}    &       nonrobust        & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                             & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{lag\\_1\\_table1}      &      -0.8256  &        0.289     &    -2.859  &         0.014        &       -1.455    &       -0.196     \\\\\n",
       "\\textbf{lag\\_2\\_table1}      &      -0.5950  &        0.284     &    -2.098  &         0.058        &       -1.213    &        0.023     \\\\\n",
       "\\textbf{lag\\_3\\_table1}      &      -0.3488  &        0.267     &    -1.309  &         0.215        &       -0.930    &        0.232     \\\\\n",
       "\\textbf{lag\\_1\\_table2}      &       0.1193  &        0.083     &     1.444  &         0.174        &       -0.061    &        0.299     \\\\\n",
       "\\textbf{lag\\_2\\_table2}      &       0.1205  &        0.066     &     1.832  &         0.092        &       -0.023    &        0.264     \\\\\n",
       "\\textbf{lag\\_3\\_table2}      &       0.0148  &        0.065     &     0.226  &         0.825        &       -0.127    &        0.157     \\\\\n",
       "\\textbf{T}                   &       4.1096  &        8.101     &     0.507  &         0.621        &      -13.540    &       21.759     \\\\\n",
       "\\textbf{overall\\_covariance} &   -1.067e-05  &     3.48e-05     &    -0.307  &         0.764        &    -8.65e-05    &     6.52e-05     \\\\\n",
       "\\textbf{lags\\_variance}      &       0.0002  &        0.000     &     1.371  &         0.195        &    -9.87e-05    &        0.000     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  1.094 & \\textbf{  Durbin-Watson:     } &    2.484  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.579 & \\textbf{  Jarque-Bera (JB):  } &    0.154  \\\\\n",
       "\\textbf{Skew:}          &  0.046 & \\textbf{  Prob(JB):          } &    0.926  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.409 & \\textbf{  Cond. No.          } & 7.30e+06  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 7.3e+06. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                             OLS Regression Results                             \n",
       "================================================================================\n",
       "Dep. Variable:     patient_count_table1   R-squared:                       0.999\n",
       "Model:                              OLS   Adj. R-squared:                  0.999\n",
       "Method:                   Least Squares   F-statistic:                     1860.\n",
       "Date:                  Wed, 15 May 2024   Prob (F-statistic):           2.29e-17\n",
       "Time:                          11:50:31   Log-Likelihood:                -92.637\n",
       "No. Observations:                    21   AIC:                             203.3\n",
       "Df Residuals:                        12   BIC:                             212.7\n",
       "Df Model:                             8                                         \n",
       "Covariance Type:              nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "lag_1_table1          -0.8256      0.289     -2.859      0.014      -1.455      -0.196\n",
       "lag_2_table1          -0.5950      0.284     -2.098      0.058      -1.213       0.023\n",
       "lag_3_table1          -0.3488      0.267     -1.309      0.215      -0.930       0.232\n",
       "lag_1_table2           0.1193      0.083      1.444      0.174      -0.061       0.299\n",
       "lag_2_table2           0.1205      0.066      1.832      0.092      -0.023       0.264\n",
       "lag_3_table2           0.0148      0.065      0.226      0.825      -0.127       0.157\n",
       "T                      4.1096      8.101      0.507      0.621     -13.540      21.759\n",
       "overall_covariance -1.067e-05   3.48e-05     -0.307      0.764   -8.65e-05    6.52e-05\n",
       "lags_variance          0.0002      0.000      1.371      0.195   -9.87e-05       0.000\n",
       "==============================================================================\n",
       "Omnibus:                        1.094   Durbin-Watson:                   2.484\n",
       "Prob(Omnibus):                  0.579   Jarque-Bera (JB):                0.154\n",
       "Skew:                           0.046   Prob(JB):                        0.926\n",
       "Kurtosis:                       3.409   Cond. No.                     7.30e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 7.3e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegModel('l1')\n",
    "lr.load_data(t1, t2)\n",
    "lr.combine_data()\n",
    "lr.get_covarience()\n",
    "lr.calculate_lag_covariance()\n",
    "lr.fit_model()\n",
    "lr.generate_prediction()\n",
    "lr.combined_df\n",
    "lr.models.summary()\n",
    "# lr.combined_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year    covariance\n",
      "0   2003  2.131532e+06\n",
      "1   2004  1.686647e+06\n",
      "2   2005  1.347950e+06\n",
      "3   2006  1.050882e+06\n",
      "4   2007  7.249912e+05\n",
      "5   2008  5.414925e+05\n",
      "6   2009  3.704825e+05\n",
      "7   2010  2.827878e+05\n",
      "8   2011  3.520552e+05\n",
      "9   2012  1.675815e+05\n",
      "10  2013  1.238298e+05\n",
      "11  2014  1.326330e+05\n",
      "12  2015  5.820100e+04\n",
      "13  2016  3.746783e+04\n",
      "14  2017  5.916900e+04\n",
      "15  2018  3.809100e+04\n",
      "16  2019  2.128933e+04\n",
      "17  2020  1.877017e+04\n",
      "18  2021  1.543783e+04\n",
      "19  2022  1.402600e+04\n",
      "20  2023  4.582667e+03\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "data = {\n",
    "    'year': range(2003, 2024),\n",
    "    'patient_count_table1': [2574, 2250, 1891, 1705, 1426, 1338, 1099, 918, 869, 716, 590, 573, 494, 406, 369, 324, 286, 247, 193, 210, 155],\n",
    "    'lag_1_table1': [3005, 2574, 2250, 1891, 1705, 1426, 1338, 1099, 918, 869, 716, 590, 573, 494, 406, 369, 324, 286, 247, 193, 210],\n",
    "    'lag_2_table1': [3397, 3005, 2574, 2250, 1891, 1705, 1426, 1338, 1099, 918, 869, 716, 590, 573, 494, 406, 369, 324, 286, 247, 193],\n",
    "    'lag_3_table1': [3885, 3397, 3005, 2574, 2250, 1891, 1705, 1426, 1338, 1099, 918, 869, 716, 590, 573, 494, 406, 369, 324, 286, 247],\n",
    "    'patient_count_table2': [25480, 22269, 19321, 17016, 14666, 13117, 11255, 9782, 8348, 7269, 6455, 5641, 4882, 4222, 3679, 3182, 2777, 2380, 2164, 1772, 1563],\n",
    "    'lag_1_table2': [29378, 25480, 22269, 19321, 17016, 14666, 13117, 11255, 9782, 8348, 7269, 6455, 5641, 4882, 4222, 3679, 3182, 2777, 2380, 2164, 1772],\n",
    "    'lag_2_table2': [33684, 29378, 25480, 22269, 19321, 17016, 14666, 13117, 11255, 9782, 8348, 7269, 6455, 5641, 4882, 4222, 3679, 3182, 2777, 2380, 2164],\n",
    "    'lag_3_table2': [39029, 33684, 29378, 25480, 22269, 19321, 17016, 14666, 13117, 11255, 9782, 8348, 7269, 6455, 5641, 4882, 4222, 3679, 3182, 2777, 2380]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Function to calculate the covariance between the lagged values of two tables\n",
    "def calculate_covariance(row, num_lags):\n",
    "    table1_lags = np.array([row[f'lag_{i}_table1'] for i in range(1, num_lags+1)])\n",
    "    table2_lags = np.array([row[f'lag_{i}_table2'] for i in range(1, num_lags+1)])\n",
    "    covariance_matrix = np.cov(table1_lags, table2_lags)\n",
    "    return covariance_matrix[0, 1]\n",
    "\n",
    "# Compute the covariance for each row and store it in a new column\n",
    "df['covariance'] = df.apply(calculate_covariance, num_lags= 3, axis=1)\n",
    "\n",
    "print(df[['year', 'covariance']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year  overall_covariance\n",
      "0   2003        2.131532e+06\n",
      "1   2004        1.686647e+06\n",
      "2   2005        1.347950e+06\n",
      "3   2006        1.050882e+06\n",
      "4   2007        7.249912e+05\n",
      "5   2008        5.414925e+05\n",
      "6   2009        3.704825e+05\n",
      "7   2010        2.827878e+05\n",
      "8   2011        3.520552e+05\n",
      "9   2012        1.675815e+05\n",
      "10  2013        1.238298e+05\n",
      "11  2014        1.326330e+05\n",
      "12  2015        5.820100e+04\n",
      "13  2016        3.746783e+04\n",
      "14  2017        5.916900e+04\n",
      "15  2018        3.809100e+04\n",
      "16  2019        2.128933e+04\n",
      "17  2020        1.877017e+04\n",
      "18  2021        1.543783e+04\n",
      "19  2022        1.402600e+04\n",
      "20  2023        4.582667e+03\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 示例数据\n",
    "data = {\n",
    "    'year': [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023],\n",
    "    'patient_count_table1': [2574, 2250, 1891, 1705, 1426, 1338, 1099, 918, 869, 716, 590, 573, 494, 406, 369, 324, 286, 247, 193, 210, 155],\n",
    "    'lag_1_table1': [3005, 2574, 2250, 1891, 1705, 1426, 1338, 1099, 918, 869, 716, 590, 573, 494, 406, 369, 324, 286, 247, 193, 210],\n",
    "    'lag_2_table1': [3397, 3005, 2574, 2250, 1891, 1705, 1426, 1338, 1099, 918, 869, 716, 590, 573, 494, 406, 369, 324, 286, 247, 193],\n",
    "    'lag_3_table1': [3885, 3397, 3005, 2574, 2250, 1891, 1705, 1426, 1338, 1099, 918, 869, 716, 590, 573, 494, 406, 369, 324, 286, 247],\n",
    "    'patient_count_table2': [25480, 22269, 19321, 17016, 14666, 13117, 11255, 9782, 8348, 7269, 6455, 5641, 4882, 4222, 3679, 3182, 2777, 2380, 2164, 1772, 1563],\n",
    "    'lag_1_table2': [29378, 25480, 22269, 19321, 17016, 14666, 13117, 11255, 9782, 8348, 7269, 6455, 5641, 4882, 4222, 3679, 3182, 2777, 2380, 2164, 1772],\n",
    "    'lag_2_table2': [33684, 29378, 25480, 22269, 19321, 17016, 14666, 13117, 11255, 9782, 8348, 7269, 6455, 5641, 4882, 4222, 3679, 3182, 2777, 2380, 2164],\n",
    "    'lag_3_table2': [39029, 33684, 29378, 25480, 22269, 19321, 17016, 14666, 13117, 11255, 9782, 8348, 7269, 6455, 5641, 4882, 4222, 3679, 3182, 2777, 2380],\n",
    "    'T': list(range(1, 22))\n",
    "}\n",
    "\n",
    "# 转换为 DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 计算总协方差并添加到 DataFrame\n",
    "covariances = []\n",
    "for index, row in df.iterrows():\n",
    "    # 提取当前行的 table1 和 table2 的滞后值\n",
    "    lags_table1 = [row['lag_1_table1'], row['lag_2_table1'], row['lag_3_table1']]\n",
    "    lags_table2 = [row['lag_1_table2'], row['lag_2_table2'], row['lag_3_table2']]\n",
    "    \n",
    "    # 计算两组滞后值的协方差矩阵，并获取协方差值\n",
    "    covariance_value = np.cov(lags_table1, lags_table2)[0, 1]\n",
    "    covariances.append(covariance_value)\n",
    "\n",
    "# 添加协方差列到 DataFrame\n",
    "df['overall_covariance'] = covariances\n",
    "\n",
    "# 打印结果\n",
    "print(df[['year', 'overall_covariance']])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
